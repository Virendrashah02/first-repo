{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0aHjnYN7bs568IrjBj+lU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Virendrashah02/first-repo/blob/main/neural_networks_in_pyhton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python Demonstration: Neural Networks Using TensorFlow/Keras\n",
        "\n",
        "We will demonstrate a simple neural network to classify the Iris Dataset,\n",
        " which contains information about different species of flowers."
      ],
      "metadata": {
        "id": "1MYgGiuwJDZt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8D_oFbUI1a0",
        "outputId": "04b3dd72-a31a-492e-a1bd-43e4dee918af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.2828 - loss: 1.2997 - val_accuracy: 0.2083 - val_loss: 1.3392\n",
            "Epoch 2/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3608 - loss: 1.1477 - val_accuracy: 0.2083 - val_loss: 1.2886\n",
            "Epoch 3/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3329 - loss: 1.1577 - val_accuracy: 0.2083 - val_loss: 1.2458\n",
            "Epoch 4/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3402 - loss: 1.1232 - val_accuracy: 0.2083 - val_loss: 1.2220\n",
            "Epoch 5/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3654 - loss: 1.0909 - val_accuracy: 0.2083 - val_loss: 1.2072\n",
            "Epoch 6/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3372 - loss: 1.1094 - val_accuracy: 0.2083 - val_loss: 1.1919\n",
            "Epoch 7/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4081 - loss: 1.0594 - val_accuracy: 0.2083 - val_loss: 1.1860\n",
            "Epoch 8/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4302 - loss: 1.0760 - val_accuracy: 0.2083 - val_loss: 1.1742\n",
            "Epoch 9/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4058 - loss: 1.0702 - val_accuracy: 0.2083 - val_loss: 1.1676\n",
            "Epoch 10/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4024 - loss: 1.0723 - val_accuracy: 0.2083 - val_loss: 1.1594\n",
            "Epoch 11/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4355 - loss: 1.0569 - val_accuracy: 0.2083 - val_loss: 1.1557\n",
            "Epoch 12/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4577 - loss: 1.0379 - val_accuracy: 0.2083 - val_loss: 1.1539\n",
            "Epoch 13/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4169 - loss: 1.0606 - val_accuracy: 0.2083 - val_loss: 1.1442\n",
            "Epoch 14/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4402 - loss: 1.0604 - val_accuracy: 0.2083 - val_loss: 1.1375\n",
            "Epoch 15/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4633 - loss: 1.0430 - val_accuracy: 0.2083 - val_loss: 1.1326\n",
            "Epoch 16/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4565 - loss: 1.0288 - val_accuracy: 0.2083 - val_loss: 1.1246\n",
            "Epoch 17/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4473 - loss: 1.0358 - val_accuracy: 0.2083 - val_loss: 1.1167\n",
            "Epoch 18/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5436 - loss: 1.0102 - val_accuracy: 0.2083 - val_loss: 1.1062\n",
            "Epoch 19/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5060 - loss: 1.0287 - val_accuracy: 0.2500 - val_loss: 1.0934\n",
            "Epoch 20/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4968 - loss: 1.0213 - val_accuracy: 0.2500 - val_loss: 1.0831\n",
            "Epoch 21/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5653 - loss: 0.9929 - val_accuracy: 0.2500 - val_loss: 1.0742\n",
            "Epoch 22/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5289 - loss: 0.9995 - val_accuracy: 0.2500 - val_loss: 1.0635\n",
            "Epoch 23/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5498 - loss: 0.9713 - val_accuracy: 0.2500 - val_loss: 1.0565\n",
            "Epoch 24/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5892 - loss: 0.9543 - val_accuracy: 0.2917 - val_loss: 1.0449\n",
            "Epoch 25/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5427 - loss: 0.9624 - val_accuracy: 0.2500 - val_loss: 1.0349\n",
            "Epoch 26/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5572 - loss: 0.9225 - val_accuracy: 0.2500 - val_loss: 1.0252\n",
            "Epoch 27/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5147 - loss: 0.9280 - val_accuracy: 0.2500 - val_loss: 1.0116\n",
            "Epoch 28/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5619 - loss: 0.8996 - val_accuracy: 0.2500 - val_loss: 1.0008\n",
            "Epoch 29/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5261 - loss: 0.9013 - val_accuracy: 0.2500 - val_loss: 0.9921\n",
            "Epoch 30/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5071 - loss: 0.8950 - val_accuracy: 0.2500 - val_loss: 0.9816\n",
            "Epoch 31/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5179 - loss: 0.8487 - val_accuracy: 0.2500 - val_loss: 0.9734\n",
            "Epoch 32/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5669 - loss: 0.8573 - val_accuracy: 0.2500 - val_loss: 0.9621\n",
            "Epoch 33/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5840 - loss: 0.8625 - val_accuracy: 0.2500 - val_loss: 0.9508\n",
            "Epoch 34/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5734 - loss: 0.8298 - val_accuracy: 0.2917 - val_loss: 0.9390\n",
            "Epoch 35/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6201 - loss: 0.8160 - val_accuracy: 0.4167 - val_loss: 0.9290\n",
            "Epoch 36/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6197 - loss: 0.8066 - val_accuracy: 0.4167 - val_loss: 0.9179\n",
            "Epoch 37/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6142 - loss: 0.8058 - val_accuracy: 0.4167 - val_loss: 0.9089\n",
            "Epoch 38/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6221 - loss: 0.7419 - val_accuracy: 0.4167 - val_loss: 0.8996\n",
            "Epoch 39/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6757 - loss: 0.6882 - val_accuracy: 0.4167 - val_loss: 0.8914\n",
            "Epoch 40/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6405 - loss: 0.7455 - val_accuracy: 0.5000 - val_loss: 0.8801\n",
            "Epoch 41/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6173 - loss: 0.7796 - val_accuracy: 0.5000 - val_loss: 0.8714\n",
            "Epoch 42/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6698 - loss: 0.7524 - val_accuracy: 0.5000 - val_loss: 0.8657\n",
            "Epoch 43/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6958 - loss: 0.7193 - val_accuracy: 0.5000 - val_loss: 0.8594\n",
            "Epoch 44/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7418 - loss: 0.7346 - val_accuracy: 0.5000 - val_loss: 0.8516\n",
            "Epoch 45/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7308 - loss: 0.6357 - val_accuracy: 0.5000 - val_loss: 0.8460\n",
            "Epoch 46/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6695 - loss: 0.7107 - val_accuracy: 0.5000 - val_loss: 0.8382\n",
            "Epoch 47/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7075 - loss: 0.7082 - val_accuracy: 0.5000 - val_loss: 0.8333\n",
            "Epoch 48/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7720 - loss: 0.6276 - val_accuracy: 0.5000 - val_loss: 0.8282\n",
            "Epoch 49/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7438 - loss: 0.6659 - val_accuracy: 0.5000 - val_loss: 0.8220\n",
            "Epoch 50/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6545 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.8171\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.6333 - loss: 0.6953\n",
            "Test Loss: 0.6953\n",
            "Test Accuracy: 0.6333\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "Predicted classes: [1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0]\n",
            "True classes: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load the Iris dataset--------------------------------------------------------------------------------------------\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features (sepal length, sepal width, petal length, petal width)\n",
        "y = iris.target  # Target labels (0, 1, 2 for three species)\n",
        "\n",
        "# One-hot encode the target labels\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_encoded = encoder.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "# Split into training and testing datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "#--------------------------BUILD NEURAL NETWORKS---------------------\n",
        "# Initialize the neural network\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer and first hidden layer with 8 neurons and ReLU activation\n",
        "model.add(Dense(8, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "\n",
        "# Second hidden layer with 8 neurons\n",
        "model.add(Dense(8, activation='relu'))\n",
        "\n",
        "# Output layer with 3 neurons (for 3 classes) and softmax activation\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "  # COMPILE THE MODEL-------------------\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "#--------------------------TRAIN THE MODEL ------------\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.2)\n",
        "\n",
        "\n",
        "#--------------------------- EVALUTE THE MODEL -------------\n",
        "# Evaluate on test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "#!!!!!-----------------MAKE PREDICTION ON THE DATA ------------------\n",
        "# Make predictions on test data\n",
        "predictions = model.predict(X_test)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(f\"Predicted classes: {predicted_classes}\")\n",
        "print(f\"True classes: {true_classes}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Progress: The training process shows the model's loss and accuracy\n",
        "improving over epochs on both training and validation data.\n",
        "\n",
        "Evaluation: The test accuracy indicates how well the model generalizes to unseen data.\n",
        "\n",
        "Predictions: The predicted classes are the neural network's guesses for each test sample.\n"
      ],
      "metadata": {
        "id": "Z4sEej34KYZ8"
      }
    }
  ]
}