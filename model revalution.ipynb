{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6eShZPQyPby1W16BmxJw7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Virendrashah02/first-repo/blob/main/model%20revalution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** How to Perform Model Evaluation Using Python**"
      ],
      "metadata": {
        "id": "X8uj0GHeX5l-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voOtqE_2WQbS",
        "outputId": "ab9e6a1b-e731-45d4-8575-499fd660c9fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 61   2]\n",
            " [  2 106]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        63\n",
            "           1       0.98      0.98      0.98       108\n",
            "\n",
            "    accuracy                           0.98       171\n",
            "   macro avg       0.97      0.97      0.97       171\n",
            "weighted avg       0.98      0.98      0.98       171\n",
            "\n",
            "\n",
            "ROC-AUC Score:\n",
            "0.9976484420928865\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Example dataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Load dataset\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = LogisticRegression(max_iter=5000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Probability for ROC-AUC\n",
        "\n",
        "# Evaluation Metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nROC-AUC Score:\")\n",
        "print(roc_auc_score(y_test, y_prob))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accounting for Unequal Error Costs Using Python"
      ],
      "metadata": {
        "id": "YLetmjfib-cH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Assign class weights\n",
        "weights = {0: 1, 1: 5}  # Class 1 has 5x higher cost\n",
        "model = RandomForestClassifier(class_weight=weights, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix with Class Weights:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuNsuiK3cBdf",
        "outputId": "6ff2f27a-b936-4eb5-b27e-2176819812dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix with Class Weights:\n",
            "[[ 60   3]\n",
            " [  3 105]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The weighted classifier example adjusts the importance of classes during\n",
        "training by assigning weights. Classes with higher weights are treated as more\n",
        "\n",
        "important, influencing the classifier to minimize errors on those classes\n",
        "\n",
        "True Negatives (50): Class 0 correctly identified as Class 0.\n",
        "\n",
        "False Positives (10): Class 0 incorrectly predicted as Class 1.\n",
        "\n",
        "False Negatives (2): Class 1 incorrectly predicted as Class 0.\n",
        "\n",
        "True Positives (109): Class 1 correctly identified as Class 1.\n"
      ],
      "metadata": {
        "id": "fUGqA0OKd8E9"
      }
    }
  ]
}